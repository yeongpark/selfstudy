# selfstudy

####proc sql 기본 구문(160529)
>proc sql;

>select

>from

>where

>group by

>order by

 
- proc sql; <- sql을 시작하기 위한 구문
- select 절은 data step에서 input 구문과 비슷하게, 변수를 지정해주는 것
- from 절은 data step에서 set 구문과 비슷하게 어느 데이터 셋에서 불러올지를 정하는 것
- where 절은 하나 이상의 조건으로 from에서 불러올 때, 부분집합을 만들어주는 것 data step에서 where 과 같음
- group by 절은 특정 변수에 따라 그룹을 나누는 것
- order by 절은 특정 변수에 따라 최종 쿼리를 정렬하는 것
 
다른 프로시져와는 달리, sql은 절의 순서가 중요해서, 위와 같은 순서를 유지해야함
select 와 from 절은 항상 존재해야 하며, where/group by/order by 절들은 옵션형태를 가짐
 
####<테이블을 쿼리하는 기본 예제>
>proc sql;

>select empid, jobcode, salary, salary *.06 as bonus

>from sasuser.payrollmaster

>where salary<32000

>order by jobcode;

>quit;



proc sql로 시작하고, from 절에서 지정된 sasuser.payrollmaster 라는 데이터셋에서 where 절에서 지정된 조건 salary 가 32000 보다 작은 관찰치만을 불러와서, select 절에서 지정된, empid, jobcode, salary, bonus를 만드는데, bonus는 salary에 .06을 곱한 값, 다음과 같은 형태를 alias 라고 부름 출력에는 empid, jobcode, salary, bonus 만이 나옴 마지막으로 결과값은 jobcode에 따라 정렬함

----------
####통계의 힘(160601)


#### <i class="icon-pencil"></i> 프롤로그

통계학을 왜 공부해야 하는가?
: 파악, 예측, 통찰
- 데이터를 통계적으로 분석해 어떤 업종이나 업무에서든 개인 혹은 집단 차원에서 인간의 행동을 통찰 -> 그것을 조금이나마 변화시켜 비즈니스 이익을 높이려함

통계학은 도메인별로 사용되는 방법이 다름 
- 농업/공업에서는 실험설계, 문자/음성/자연어 처리를 자동화하는 머신러닝 등

또한, 분석하려는 목적에 따라 통계학을 세 가지로 분류함
: 현상 파악, 인과관계 통찰, 미래 예측 -> 책에서는 인과관계 통찰을 주로 이야기 함

>현상파악 : 마케팅 조사에서 “현재 특정 제품을 사용하는 사람이 몇 명인지 정확하게 추정하는 것” 등을 말함. 조사를 통해 추정되는 평균과 비율을 그래프에 정리하는 작업은 대다수 비즈니스 종사자들이 어렵지 않게 하고 있어 책에서 굳이 다루지 않음

>미래예측 : 앞으로 주가나 원자재 가격이 상승할지 혹은 재고가 어떻게 변할지 같은 것을 정확히 예측하려는 것. 또는 머신러닝에서의 음성의 인식 등 ‘인간이라면 어떻게 인식하는가’하는 부분을 데이터로 정확히 예측함으로써 인간의 인지를 모방하려는 사고방식도 여기에 해당. 이 책에서 이를 다루지 않는 이유는, 분석방법 운운하기 전에 그 밖의 여러 사정 때문에 실제 예측을 현실화하는 것이 매우 어렵기 때문.

>통찰의 통계학 : 마케팅에서는 ‘이 상품이 몇 개 팔릴까?’ 보단 ‘어떤 홍보를 해야 효과가 있을까?’, ‘어떻게 광고해야 히트상품이 될까?’를 더 중요시함. 즉, 그 인과관계를 찾아야 함


####2. 제 1장

2.1 통찰의 통계학에 필요한 세 가지 지식

: 평균 vs 비율
- continuous variable은 평균으로, categorical variable은 비율(해당하는 정도)로 나타냄

: 데이터는 점(평균 또는 비율)이 아니라 구간
- 그러나 한 점으로 표현하면 데이터의 많은 정보를 놓침
- 따라서 통계학은 ‘데이터는 대체로 어디에서 어디까지의 범위에 속해있는가’하는 식의 구간으로 파악하는 방법을 고안

: ‘무슨 값을 어떻게 정리해야 하는지’에 대한 이해
- 원인과 결과(outcome)를 잘 정의해야 함
- 비즈니스에서 가치 있는 데이터 분석은 ‘최대화하거나 최소화해야하는 항목’이 무엇인지 알아내는 것

: 설명변수의 우선순위 매기는 방법
- 인과관계가 너무 당연한 것이어서는 안된다
- 아웃컴에 미치는 영향이 명백하더라도 조절이 가능해야 한다
- 지금까지 그다지 주목 받지 않고 분석된 적이 별로 없어야 한다

2.2 인과관계 파악에 중요한 ‘평균’의 본질

- ‘현상파악’에서 데이터의 대푯값 : 평균, 중위수, 최빈값
- 통찰을 위한 통계학에서는 중앙값과 최빈수에 신경쓰는 일이 거의 없다
- 관측값과 참값의 차이(절댓값)을 최소로 만드는 추측값은 “중앙값”
- 그러나 절댓값 계산이 어려워 차이의 제곱을 최소로하는 추측값을 찾았는데 이게 “평균” by가우스
- 즉 평균은 최소제곱법에 기초하여 측정값에 포함되어 있는 차이를 가장 적게 만드는 뛰어난 추정값임

2.3 어떻게 평균으로 진실을 포착할 수 있는가
- 인과관계 통찰 관점에서 볼 때 평균값이 중앙값보다 관심이 있는 것에 대한 직접적인 대답이 되는 경우가 많다
- 인과관계 통찰할 때는 어떤 결과를 나타내는 값의 ‘총량’을 최대화하거나 최소화하느 쪽으로 관심이 쏠리게 마련인데 ‘뭔가의 요인을 바꾸면 결과값의 총량이 어떻게 변하는가’ 하는 부분에 중앙값은 속 시원한 대답을 못함
- 또한 왜 평균값을 불규칙성이 내포된 데이터의 배후에 있는 ‘참값’이라고 생각해도 되는지 가우스가 이야기 함
- 가우스의 질문 “평균값을 사용하는 것이 참값을 추정하는 좋은 방법이 되는 조건이란 무엇인가” 에서 정규분포라 불리는 ‘불규칙의 법칙성’에 이르게 됨
- 즉, 데이터의 불규칙성이 정규분포를 따르고 있으면 최소제곱법이 가장 좋은 추정 방법이고, 그 결과 평균값이 가장 좋은 추정값이 된다.

2.4 정규분포
- 좌우대칭인 종 모양의 매끄러운 곡선으로 표현되는 데이터의 불규칙성
- 그래프의 가로축은 변수, 세로축은 데이터 전체에서 차지하는 비율. 즉, 이 집단에서 임의로 뽑아낸 1명의 변수값이 어떠한가 하는 확률을 의미(밀도)

2.5 중심극한정리(CLT, Central Limit Theorem)
- 데이터가 정규분포를 따르지 않는다고 해도 ‘데이터 값을 거듭 추가할수록 정규분포에 수렴’ 
- 데이터 값을 몇개 추가한 것이 정규분포를 따르면, 거기에 다시 ‘추가한 데이터의 수’로 나눈 값인 평균값도 정규분포에 수렴함
그렇기에 ‘원시데이터의 불규칙성과 그것의 평균값’과 ‘원시데이터의 불규칙성과는 상관없는, 평균값 자체의 불규칙성’의 구별이 중요함

2.7 표준편차로 데이터의 대략적 범위를 알 수 있다
- 사분위수, 백분위수(현상파악에서 제시)
- 분산, 표준편차

